
üìÑ Compte rendu ‚Äì Sentiment Analysis sur Actualit√©s Financi√®res (MoE / MoMoE)
=============================================================================
Par El YESRI INASS 
<img width="100" height="150" alt="image" src="https://github.com/user-attachments/assets/8ff73355-eaf0-42d3-ac75-12fdc08df8d2" />

1\. Le Contexte M√©tier et la Mission
------------------------------------

### Le Probl√®me (Business Case)

Dans la finance, les march√©s r√©agissent en quelques secondes aux **news √©conomiques** :publication de r√©sultats, annonces de banques centrales, fusions, faillites, etc.

Aujourd‚Äôhui, les g√©rants de portefeuille et les traders :

*   lisent manuellement des dizaines de titres par jour,
    
*   √©valuent ¬´ √† la main ¬ª si la nouvelle est **positive**, **n√©gative** ou **neutre**,
    
*   risquent des **biais humains** (fatigue, subjectivit√©, √©motions).
    

üëâ **Objectif du projet** :Construire un syst√®me d‚Äô**analyse automatique de sentiment** qui classe chaque titre de news financi√®res en :

*   negative
    
*   neutral
    
*   positive
    

afin d‚Äôaider √† **prioriser** les informations et, √† terme, d‚Äôalimenter des mod√®les de **pr√©diction de mouvements de march√©**.

### L‚ÄôEnjeu critique

Toutes les erreurs ne se valent pas :

*   Classer une tr√®s mauvaise nouvelle en _neutral_ ‚Üí risque de **sous-r√©agir** (pertes potentielles).
    
*   Classer une news neutre en _negative_ ‚Üí risque de **sur-r√©agir** (ventes inutiles, co√ªts d‚Äôopportunit√©).
    

üéØ **Enjeu :**R√©duire **surtout** les erreurs sur les sentiments _extr√™mes_ (tr√®s positif / tr√®s n√©gatif) qui d√©clenchent des d√©cisions fortes (achat/vente).

2\. Les Donn√©es (L‚ÄôInput)
-------------------------

La dataset utilis√©e est le fichier Kaggle all-data (1).csv :

*   **Colonnes principales** :
    
    *   sentiment : negative, neutral, positive
        
    *   text : titre de la news financi√®re
        

Dans le notebook :

```python
df = pd.read_csv("all-data (1).csv", encoding="latin-1")  df.columns = ['sentiment', 'text']
````

### Analyse des donn√©es brutes

*   V√©rification de la taille : df.shape
    
*   Inspection rapide : df.head(), df.tail()
    
*   V√©rification des doublons : df.duplicated().sum()
    
*   V√©rification des valeurs manquantes : df.isnull().sum()
    
*   Information sur les types : df.info()
    
*   Nombre de valeurs distinctes : df.nunique()
    

üëâ **Constat :**

*   Les textes sont **courts** (titres, pas des articles complets).
    
*   Les labels sentiment sont **d√©s√©quilibr√©s** (une classe plus fr√©quente, souvent _neutral_).
    
*   Il existe des **doublons** qui sont supprim√©s avec :
    
```python
df = df.drop_duplicates()
``` `

3\. Le Code Python (Laboratoire)
--------------------------------

Ton notebook joue le r√¥le de **laboratoire exp√©rimental**. Il encha√Æne les grandes phases suivantes :

1.  **Chargement & nettoyage de base** (read\_csv, suppression des doublons, gestion des NaN).
    
2.  **Pr√©traitement NLP** : fonction clean\_text (lowercase, stopwords, lemmatisation, etc.).
    
3.  **Visualisation simple des classes** : countplot sur sentiment.
    
4.  **√âquilibrage des classes** (upsampling avec resample ‚Üí df\_balanced).
    
5.  **Exploration du vocabulaire** : wordclouds & top words par sentiment.
    
6.  **Repr√©sentation des textes** :
    
    *   embeddings de phrase via SentenceTransformer('all-MiniLM-L6-v2') (dimension dense),
        
    *   TF-IDF bigrammes comme autre vue textuelle.
        
7.  **Architecture Mixture-of-Experts (MoE)** :
    
    *   d√©finition d‚ÄôExpert, SwiGLU, MoEHead,
        
    *   entra√Ænement sur les embeddings.
        
8.  **Agents additionnels** :
    
    *   agent2 = Logistic Regression sur TF-IDF,
        
    *   agent3 = RandomForestClassifier sur TF-IDF.
        
9.  **Meta-Model (MoMoE)** :
    
    *   concat√©ner les sorties (probabilit√©s) MoE + agent2 + agent3,
        
    *   entra√Æner un dernier classifieur meta\_clf.
        
10.  **√âvaluation** :
    
    *   accuracy\_score, classification\_report,
        
    *   confusion\_matrix ‚Üí heatmaps pour **MoE** et **MoMoE**.
        

4\. Analyse approfondie : Nettoyage & Pr√©traitement (Data Wrangling)
--------------------------------------------------------------------

### 4.1. Nettoyage des doublons et valeurs manquantes

Tu supprimes :

*   les lignes dupliqu√©es,
    
*   les √©ventuelles valeurs manquantes dans le texte :
    

```python
df = df.drop_duplicates()  df.isnull().sum()
````

üß† **Analyse :**

*   En NLP, des doublons peuvent **biaiser** l‚Äôapprentissage : le mod√®le ¬´ revoit deux fois la m√™me phrase ¬ª, ce qui renforce artificiellement son importance.
    
*   Sur ce projet, supprimer les doublons permet d‚Äôobtenir une estimation plus fid√®le des performances sur de **nouvelles news**.
    

### 4.2. Fonction de pr√©traitement clean\_text

La fonction clean\_text (reconstruite √† partir de ton notebook) r√©alise typiquement :

*   Mise en minuscules,
    
*   Suppression des chiffres : re.sub(r'\\d+', '', text)
    
*   Suppression de la ponctuation : re.sub(r'\[^\\w\\s\]', '', text)
    
*   Normalisation des espaces : re.sub(r'\\s+', ' ', text).strip()
    
*   Suppression des stopwords + lemmatisation (ex : organisations ‚Üí organisation)
    

Plain textANTLR4BashCC#CSSCoffeeScriptCMakeDartDjangoDockerEJSErlangGitGoGraphQLGroovyHTMLJavaJavaScriptJSONJSXKotlinLaTeXLessLuaMakefileMarkdownMATLABMarkupObjective-CPerlPHPPowerShell.propertiesProtocol BuffersPythonRRubySass (Sass)Sass (Scss)SchemeSQLShellSwiftSVGTSXTypeScriptWebAssemblyYAMLXML`   df['clean_text'] = df['text'].apply(clean_text)  df = df[['clean_text', 'sentiment']]   `

üß† **Analyse : Pourquoi c‚Äôest important ?**

*   Les mod√®les MoE + logistic regression travaillent sur des **repr√©sentations num√©riques** ‚Üí bruit lexical inutile = dimension inutile.
    
*   La lemmatisation permet de **regrouper** les formes fl√©chies d‚Äôun m√™me mot (profit / profits / profited‚Ä¶).
    
*   Les stopwords comme the, and, of n‚Äôapportent presque aucune information sur le **sentiment** ‚Üí on gagne en signal/bruit.
    

5\. Analyse approfondie : √âquilibrage & Exploration (EDA)
---------------------------------------------------------

### 5.1. D√©s√©quilibre des classes & upsampling

Tu utilises un **r√©-√©chantillonnage par sur-√©chantillonnage** (upsampling) pour √©quilibrer les classes :
```python
from sklearn.utils import resample  classes = df['sentiment'].unique()  max_count = df['sentiment'].value_counts().max()  df_list = []  for c in classes:      df_class = df[df['sentiment'] == c]      df_upsampled = resample(df_class,                              replace=True,                              n_samples=max_count,                              random_state=42)      df_list.append(df_upsampled)  df_balanced = pd.concat(df_list)  df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)
```

üß† **Analyse :**

*   Sans √©quilibrage, le mod√®le pourrait devenir ¬´ paresseux ¬ª et pr√©dire **majoritairement la classe dominante** (souvent _neutral_).
    
*   L‚Äôupsampling rend les trois sentiments **√©quitablement repr√©sent√©s** ‚Üí le mod√®le est oblig√© de **se sp√©cialiser** pour reconna√Ætre chaque sentiment.
    

‚ö†Ô∏è **Limite** :L‚Äôupsampling r√©p√®te des phrases d√©j√† vues ‚Üí risque de **surapprentissage** entendu. Ici, l‚Äôutilisation d‚Äôun MoE + r√©gularisation et split train/test r√©duit ce risque, mais c‚Äôest un point √† surveiller.

### 5.2. Visualisation des sentiments

Avec :

```python
plt.figure(figsize=(6,4))  sns.countplot(x=df['sentiment'])  plt.title("Sentiment Count Plot")
```

puis sur df\_balanced apr√®s upsampling.

üß† **Analyse :**

*   Avant √©quilibrage : on voit le **d√©s√©quilibre** (ex : plus de neutral).
    
*   Apr√®s √©quilibrage : les trois barres sont de **hauteur similaire** ‚Üí condition n√©cessaire pour entra√Æner un meta-mod√®le robuste qui ne n√©glige pas les sentiments minoritaires.
    

### 5.3. WordClouds & Top Words

Tu g√©n√®res :

*   un wordcloud global (all\_text = " ".join(df\['clean\_text'\])),
    
*   des wordclouds par sentiment (for c in unique\_classes),
    
*   un graphique des **Top N mots par sentiment** :
    

```python
from collections import Counter  def plot_top_words(df, sentiment_col='sentiment', text_col='clean_text', top_n=10):      sentiments = df[sentiment_col].unique()      for s in sentiments:          texts = df[df[sentiment_col] == s][text_col]          all_words = " ".join(texts).split()          word_counts = Counter(all_words).most_common(top_n)          ...
```

üß† **Analyse :**

*   Les wordclouds permettent d‚Äôidentifier les **mots typiques** :
    
    *   positive : _growth, profit, upbeat, surge, beat estimates‚Ä¶_
        
    *   negative : _loss, drop, downgrade, miss, slump, crisis‚Ä¶_
        
    *   neutral : _announces, reports, said, plans‚Ä¶_
        
*   √áa valide l‚Äôhypoth√®se que le sentiment est **corr√©l√© au vocabulaire**, ce qui justifie une approche machine learning supervis√©e.
    

6\. Analyse approfondie : M√©thodologie (Split & Repr√©sentation)
---------------------------------------------------------------

### 6.1. Encodage des labels

Tu cr√©es une version num√©rique du sentiment :

```python
mapping = {'positive': 1, 'neutral': 0, 'negative': -1}  df_balanced['sentiment_num'] = df_balanced['sentiment'].map(mapping)
```

üß† **Analyse :**

*   Cet encodage garde la **structure ordinale** : -1 < 0 < 1 (n√©gatif ‚Üí neutre ‚Üí positif), ce qui est coh√©rent avec une lecture de _score_.
    
*   Plus tard, tu reviendras √† des labels humains via map({0:-1,1:0,2:1}) pour interpr√©ter les pr√©dictions.
    

### 6.2. Repr√©sentation des textes

Tu utilises deux familles de repr√©sentations :

#### a) Sentence Transformer (Embeddings denses)
```python
from sentence_transformers import SentenceTransformer  model = SentenceTransformer('all-MiniLM-L6-v2')  embeddings = model.encode(df_balanced["clean_text"].tolist(), show_progress_bar=True)
```

*   Chaque phrase ‚Üí vecteur dense (par ex. dimension 384).
    
*   Ces embeddings capturent **le contexte** (proche de BERT, adapt√© aux phrases).
    

üß† **Analyse :**

*   Beaucoup plus **riches** s√©mantiquement que du simple bag-of-words.
    
*   Parfait pour √™tre inject√©s dans un r√©seau type **MoE**.
    

#### b) TF-IDF (N-grammes)

```python
tfidf = TfidfVectorizer(max_features=20000, ngram_range=(1,2))  tfidf_fit_texts = df_balanced["clean_text"].astype(str).tolist()  tfidf_matrix = tfidf.fit_transform(tfidf_fit_texts)  X_train_tfidf = tfidf_matrix[idx_train]  X_test_tfidf = tfidf_matrix[idx_test]   `
```

üß† **Analyse :**

*   TF-IDF nourrit les mod√®les **lin√©aires** (Logistic Regression) et **ensemble** (RandomForest).
    
*   Les bigrammes (1,2) permettent de capturer des expressions comme _"beats estimates"_ ou _"misses expectations"_, tr√®s importantes en finance.
    

### 6.3. Split train/test & reproductibilit√©

Tu cr√©es des indices de train/test :

  ```python
  idx_train, idx_test, y_train, y_test = train_test_split(      np.arange(len(df_balanced)),       df_balanced["sentiment_num"].values,       test_size=0.2,       random_state=42,       stratify=df_balanced["sentiment_num"].values  )
```

üß† **Analyse :**

*   test\_size=0.2 ‚Üí 80% pour l‚Äôapprentissage, 20% pour l‚Äô√©valuation.
    
*   stratify ‚Üí la distribution des classes est **la m√™me** dans train et test.
    
*   random\_state=42 ‚Üí reproductibilit√© scientifique : tout le monde obtient **exactement** le m√™me split.
    

7\. FOCUS TH√âORIQUE : L‚ÄôArchitecture Mixture-of-Experts (MoE) & Meta-Model
--------------------------------------------------------------------------

Pourquoi un simple mod√®le ne suffit pas ici ?

### 7.1. Faiblesse d‚Äôun seul ¬´ expert ¬ª

Un seul mod√®le (ex : Logistic Regression ou Random Forest) :

*   peut √™tre tr√®s bon sur certains types de phrases (ex : titres simples),
    
*   mais moins performant sur des formulations plus complexes, ironiques, ou tr√®s techniques.
    

On veut **plusieurs points de vue** :

*   un mod√®le qui sait bien g√©rer la structure s√©mantique (embeddings + MoE),
    
*   un mod√®le qui sait bien exploiter des n-grammes fr√©quents (TF-IDF + LR),
    
*   un mod√®le capable de capter des interactions non-lin√©aires (TF-IDF + RandomForest).
    

### 7.2. Architecture MoE (sur Sentence Embeddings)

Dans ton code, tu d√©finis :

```python
class SwiGLU(nn.Module):      ...  class Expert(nn.Module):      def __init__(self, dim, hidden_mult=4):          ...      def forward(self, x):          ...  class MoEHead(nn.Module):      def __init__(self, dim, num_experts=4, k=2, num_classes=3):          ...      def forward(self, x):          gate_logits = self.router(x)          gate_probs = F.softmax(gate_logits, dim=-1)          # top-k experts activ√©s pour chaque sample          ...          return logits, gate_probs   `
```

üß† **Analyse :**

*   **Experts** : chaque Expert est un petit r√©seau qui apprend une **sp√©cialisation** sur certains types de phrases.
    
*   **Router** : pour chaque phrase, le router calcule une distribution de probabilit√© sur les experts ‚Üí il choisit les k meilleurs (top-k).
    
*   L‚Äôoutput final est un **m√©lange pond√©r√©** des sorties des experts, suivi d‚Äôun classifier qui donne une probabilit√© pour chaque sentiment.
    

Intuition :

> Chaque titre de news est envoy√© principalement √† **2 experts** parmi 4, ceux qui sont ¬´ le plus comp√©tents ¬ª pour ce cas particulier.

### 7.3. Agents classiques : Logistic Regression & Random Forest

```python
  agent2 = LogisticRegression(max_iter=1000)  agent2.fit(X_train_tfidf, np.array(y_train))  agent2_proba = agent2.predict_proba(X_test_tfidf)  agent3 = RandomForestClassifier(n_estimators=200, random_state=42)  agent3.fit(X_train_tfidf, np.array(y_train))  agent3_proba = agent3.predict_proba(X_test_tfidf)
```

üß† **Analyse :**

*   **Agent 2 (LR)** : stable, interpr√©table, tr√®s adapt√© pour TF-IDF (espace √† haute dimension mais lin√©airement s√©parables).
    
*   **Agent 3 (RF)** : capte des interactions non-lin√©aires entre n-grammes, robustes au bruit, mais moins interpr√©table.
    

### 7.4. Meta-Model (MoMoE) : combiner les cerveaux

Tu construis un **meta-dataset** :

*   features = concat√©nation des proba/sorties de :
    
    *   MoE (moe\_test\_proba)
        
    *   agent2 (agent2\_proba)
        
    *   agent3 (agent3\_proba)
        
*   labels = y\_test
    

Puis tu entra√Ænes un **meta classifieur** (par ex. Logistic Regression ou autre) :

```python
meta_X = np.concatenate([moe_test_proba, agent2_proba, agent3_proba], axis=1)  meta_y = y_test  meta_clf = LogisticRegression(max_iter=1000)  meta_clf.fit(meta_X, meta_y)  meta_preds = meta_clf.predict(meta_X)
```

üß† **Analyse :**

*   Le meta-model apprend **quand faire confiance √† quel expert** :
    
    *   certaines zones de l‚Äôespace des phrases ‚Üí MoE est meilleur,
        
    *   d‚Äôautres ‚Üí l‚Äôagent TF-IDF est plus fiable.
        
*   C‚Äôest une **deuxi√®me couche d‚Äôintelligence** qui orchestre les pr√©dictions.
    

8\. Analyse approfondie : √âvaluation (l‚ÄôHeure de v√©rit√©)
--------------------------------------------------------

### 8.1. Performance du MoE seul

Tu calcules :

```python
 print("MoE test accuracy:", accuracy_score(y_test, all_preds_moe))  print(classification_report(y_test, all_preds_moe, digits=4))
```

Et visualises la matrice de confusion :

```python
cm_moe = confusion_matrix(y_test, all_preds_moe)  sns.heatmap(cm_moe, annot=True, fmt='d', cmap='Blues')  plt.title("Confusion Matrix - MoE")
```

üß† **Analyse qualitative (sans chiffres exacts)** :

*   MoE se base sur des **embeddings s√©mantiques** ‚Üí tr√®s bon pour :
    
    *   reconna√Ætre des sentiments exprim√©s de mani√®re subtile,
        
    *   g√©n√©raliser √† des formulations nouvelles.
        
*   Les erreurs typiques :
    
    *   _neutral_ ‚Üî _positive_ quand le texte est vaguement optimiste,
        
    *   _neutral_ ‚Üî _negative_ quand le titre annonce un risque sans impact imm√©diat.
        

### 8.2. Performance du Meta-Model (MoMoE)

Tu calcules :
```python
print("MoMoE (meta) accuracy:", accuracy_score(meta_y, meta_preds))  print(classification_report(meta_y, meta_preds, digits=4))
```

Et la matrice de confusion :

```python
cm_momoe = confusion_matrix(meta_y, meta_preds)  sns.heatmap(cm_momoe, annot=True, fmt='d', cmap='Greens')  plt.title("Confusion Matrix - MoMoE (Meta Model)")
```

üß† **Analyse comparative MoE vs MoMoE :**

M√™me sans mettre de chiffres pr√©cis, on peut analyser la **tendance attendue** :

1.  **Accuracy globale**
    
    *   MoMoE devrait **au moins √©galer**, et souvent **l√©g√®rement d√©passer** le MoE seul, car il exploite **trois sources d‚Äôinformation** au lieu d‚Äôune.
        
2.  **Par classe (Pr√©cision / Rappel)**
    
    *   Sur la classe negative :
        
        *   logistic regression + TF-IDF est souvent tr√®s fort (mots comme _loss, slump, downgrade, miss_).
            
        *   MoMoE apprend √† peser davantage cet agent sur ce type de phrases.
            
    *   Sur la classe positive :
        
        *   m√™me logique avec des bigrammes comme _beats estimates_, _raises guidance_.
            
    *   Sur la classe neutral :
        
        *   plus ambigu√´ ‚Üí le MoE (embeddings contextuels) a une vraie valeur ajout√©e.
            
3.  **Matrice de confusion**
    
    *   Les erreurs les plus **critiques** du point de vue m√©tier :
        
        *   negative ‚Üí neutral ou positive (sous-estimer une mauvaise nouvelle),
            
        *   positive ‚Üí neutral (ne pas voir une opportunit√©).
            
    *   MoMoE devrait **r√©duire** ces erreurs par rapport au MoE seul, car il combine plusieurs regards.
        

### 8.3. Interpr√©tation m√©tier des m√©triques

En pratique, on regarde particuli√®rement :

*   **Recall sur negative** :¬´ Parmi toutes les v√©ritables mauvaises news, combien mon syst√®me en d√©tecte-t-il ? ¬ª
    
*   **Precision sur positive** :¬´ Quand il dit que c‚Äôest positif, a-t-on vraiment une bonne nouvelle, ou est-il trop optimiste ? ¬ª
    
*   **F1-score** par classe : compromis global entre Precision et Recall.
    

üëâ **Lien avec la finance :**

*   Un high Recall sur negative permet d‚Äô√©viter les **surprises catastrophiques** (crash, pertes, faillites).
    
*   Un mod√®le l√©g√®rement ¬´ parano√Øaque ¬ª (pr√©dit plus souvent negative que n√©cessaire) peut √™tre acceptable selon la **tol√©rance au risque du m√©tier**.
    

9\. Conclusion du Projet
------------------------

Ce projet montre comment passer d‚Äôun **CSV brut de titres financiers** √† un **syst√®me avanc√© de classification de sentiment** bas√© sur :

*   un pr√©traitement NLP solide (cleaning, lemmatisation, stopwords),
    
*   une gestion intelligente du **d√©s√©quilibre de classes** (upsampling),
    
*   des **repr√©sentations hybrides** (embeddings + TF-IDF),
    
*   une architecture **Mixture-of-Experts** (MoE) enrichie d‚Äôun **meta-model** (MoMoE).
    

üí° **Apport principal de l‚Äôapproche MoE / MoMoE :**

*   Au lieu de chercher **un seul mod√®le parfait**, tu combines plusieurs mod√®les qui se **compl√®tent**, avec un meta-mod√®le qui apprend _quand_ faire confiance √† quel expert.
    

üìå **Perspectives d‚Äôam√©lioration possibles :**

*   Utiliser un mod√®le pr√©-entra√Æn√© sp√©cialis√© finance : **FinBERT**.
    
*   Ajouter une dimension **temps** : relier chaque news au mouvement r√©el du march√© (backtesting).
    
*   D√©finir une **matrice de co√ªts** m√©tier (erreur sur negative plus p√©nalisante que sur neutral) et adapter la fonction de perte.
    
